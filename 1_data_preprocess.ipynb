{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json, os, sys, glob\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "from IPython.display import Image,display\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile\n",
    "from six.moves.urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download and decompress dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def may_create_folder(folder):\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "    print(\"Folder %s present now\" % folder)\n",
    "\n",
    "#may_create_folder(\"./test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ./data present now\n",
      "Downloaded and verified file : ./data/test.tar.gz\n",
      "Downloaded and verified file : ./data/train.tar.gz\n"
     ]
    }
   ],
   "source": [
    "download_site = \"http://ufldl.stanford.edu/housenumbers/\"\n",
    "data_root = \"./data\"\n",
    "last_percent_reported = None\n",
    "\n",
    "def download_progress_hook(count, blockSize, totalSize):\n",
    "  \"\"\"A hook to report the progress of a download. This is mostly intended for users with\n",
    "  slow internet connections. Reports every 5% change in download progress.\n",
    "  \"\"\"\n",
    "  global last_percent_reported\n",
    "  percent = int(count * blockSize * 100 / totalSize)\n",
    "\n",
    "  if last_percent_reported != percent:\n",
    "    if percent % 5 == 0:\n",
    "      sys.stdout.write(\"%s%%\" % percent)\n",
    "      sys.stdout.flush()\n",
    "    else:\n",
    "      sys.stdout.write(\".\")\n",
    "      sys.stdout.flush()\n",
    "      \n",
    "    last_percent_reported = percent\n",
    "\n",
    "def may_download(tar_file_name, expected_size, force = False):\n",
    "    dest_filename = os.path.join(data_root, tar_file_name)\n",
    "    if force or not os.path.exists(dest_filename):\n",
    "        print(\"Attempt to download file \" + tar_file_name)\n",
    "        file_name, _ = urlretrieve( download_site + tar_file_name, dest_filename, reporthook=download_progress_hook)\n",
    "        print(\"Download complete!\")\n",
    "    statinfo = os.stat(dest_filename)\n",
    "    if statinfo.st_size == expected_size:\n",
    "        print(\"Downloaded and verified file : \" + dest_filename)\n",
    "    else:\n",
    "        raise Exception(\"Failed to verify file : \" + dest_filename)\n",
    "    return dest_filename\n",
    "    \n",
    "may_create_folder(data_root)\n",
    "test_filename = may_download(\"test.tar.gz\", 276555967)\n",
    "train_filename = may_download(\"train.tar.gz\", 404141560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/train already present --- Skipping extraction of ./data/train.tar.gz\n",
      "./data/test already present --- Skipping extraction of ./data/test.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import os, tarfile\n",
    "\n",
    "def maybe_extract(filename, force = False):\n",
    "    root = os.path.splitext(os.path.splitext(filename)[0])[0]\n",
    "    if os.path.isdir(root) and not force:\n",
    "        print(\"{0} already present --- Skipping extraction of {1}\".format(root, filename))\n",
    "    else:\n",
    "        print(\"Extract data for {0}, this may take a while, please wait ..\".format(filename))\n",
    "        tar = tarfile.open(filename)\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "    return  root\n",
    "\n",
    "train_folders = maybe_extract(train_filename)\n",
    "test_folders = maybe_extract(test_filename)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Transform .mat file to Json file\n",
    "Use the python script taken from http://www.a2ialab.com/lib/exe/fetch.php?media=public:scripts:svhn_dataextract_tojson.py.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./data/train/digitStruct.mat', './data/test/digitStruct.mat']\n"
     ]
    }
   ],
   "source": [
    "digit_struct_files = glob.glob('./data/*/*.mat')\n",
    "print(digit_struct_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ./jsons present now\n",
      "Complete !\n"
     ]
    }
   ],
   "source": [
    "jsons_root = './jsons'\n",
    "\n",
    "def transform_mat_to_json():\n",
    "    transform_json_script = \"python svhn_dataextract_tojson.py -f ./data/{0}/digitStruct.mat -o ./jsons/{0}/digitStruct\"\n",
    "    for file_type in ['train', 'test']:\n",
    "        output_folder = os.path.join(jsons_root, file_type)\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.mkdir(output_folder)\n",
    "        if os.path.exists(os.path.join(output_folder, 'digitStruct.json')):\n",
    "            continue\n",
    "        print(\"Begin transform %s files\" % file_type)\n",
    "        os.system(transform_json_script.format(file_type))\n",
    "        print(\"End transform %s files\" % file_type)\n",
    "    print(\"Complete !\")\n",
    "    \n",
    "may_create_folder(jsons_root)\n",
    "transform_mat_to_json()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train json info : \n",
      " [{'filename': '1.png', 'bbox_x1': 246, 'bbox_y1': 77, 'boxes': array([{'left': 246, 'top': 77, 'width': 81, 'height': 219},\n",
      "       {'left': 323, 'top': 81, 'width': 96, 'height': 219}], dtype=object), 'bbox_width': 173, 'bbox_height': 223, 'labels': array([1, 9])}, {'filename': '2.png', 'bbox_x1': 77, 'bbox_y1': 25, 'boxes': array([{'left': 77, 'top': 29, 'width': 23, 'height': 32},\n",
      "       {'left': 98, 'top': 25, 'width': 26, 'height': 32}], dtype=object), 'bbox_width': 47, 'bbox_height': 36, 'labels': array([2, 3])}, {'filename': '3.png', 'bbox_x1': 17, 'bbox_y1': 5, 'boxes': array([{'left': 17, 'top': 5, 'width': 8, 'height': 15},\n",
      "       {'left': 25, 'top': 5, 'width': 9, 'height': 15}], dtype=object), 'bbox_width': 17, 'bbox_height': 15, 'labels': array([2, 5])}, {'filename': '4.png', 'bbox_x1': 57, 'bbox_y1': 13, 'boxes': array([{'left': 57, 'top': 13, 'width': 15, 'height': 34},\n",
      "       {'left': 72, 'top': 13, 'width': 13, 'height': 34}], dtype=object), 'bbox_width': 28, 'bbox_height': 34, 'labels': array([9, 3])}, {'filename': '5.png', 'bbox_x1': 52, 'bbox_y1': 7, 'boxes': array([{'left': 52, 'top': 7, 'width': 21, 'height': 46},\n",
      "       {'left': 74, 'top': 10, 'width': 15, 'height': 46}], dtype=object), 'bbox_width': 37, 'bbox_height': 49, 'labels': array([3, 1])}]\n",
      "==================================================\n",
      "Test json info : \n",
      " [{'filename': '1.png', 'bbox_x1': 43, 'bbox_y1': 7, 'boxes': array([{'left': 43, 'top': 7, 'width': 19, 'height': 30}], dtype=object), 'bbox_width': 19, 'bbox_height': 30, 'labels': array([5])}, {'filename': '2.png', 'bbox_x1': 99, 'bbox_y1': 5, 'boxes': array([{'left': 99, 'top': 5, 'width': 14, 'height': 23},\n",
      "       {'left': 114, 'top': 8, 'width': 8, 'height': 23},\n",
      "       {'left': 121, 'top': 6, 'width': 12, 'height': 23}], dtype=object), 'bbox_width': 34, 'bbox_height': 26, 'labels': array([ 2,  1, 10])}, {'filename': '3.png', 'bbox_x1': 61, 'bbox_y1': 6, 'boxes': array([{'left': 61, 'top': 6, 'width': 11, 'height': 16}], dtype=object), 'bbox_width': 11, 'bbox_height': 16, 'labels': array([6])}, {'filename': '4.png', 'bbox_x1': 32, 'bbox_y1': 6, 'boxes': array([{'left': 32, 'top': 6, 'width': 14, 'height': 17}], dtype=object), 'bbox_width': 14, 'bbox_height': 17, 'labels': array([1])}, {'filename': '5.png', 'bbox_x1': 97, 'bbox_y1': 28, 'boxes': array([{'left': 97, 'top': 28, 'width': 19, 'height': 28}], dtype=object), 'bbox_width': 19, 'bbox_height': 28, 'labels': array([9])}]\n"
     ]
    }
   ],
   "source": [
    "def get_json_information(json_file):\n",
    "    '''\n",
    "    \n",
    "    :param json_file: path of json files\n",
    "    :return: \n",
    "      result format : [{'filename':'*.png', 'bbox_x1': value, 'bbox_y1':value, 'bbox_width':value, 'bbox_height': value,\n",
    "      'boxes':np.array([{'left':value, 'top':value, 'width':value, 'height':value}, ..]), labels:np.array([val1, val2,..])}, ...]\n",
    "      'filename' : name of image file\n",
    "      'bbox_x1' : left coordinate of bounding box\n",
    "      'bbox_y1' : top coordinate of bounding box\n",
    "      'bbox_width : width of bounding box\n",
    "      'bbox_height' : height of bounding box\n",
    "      'boxes' : all box in the image\n",
    "      'boxes'.'left': left coordinate of one box\n",
    "      'boxes'.'top' : top coordinate of one box\n",
    "      'boxes'.'widht' : width of one box\n",
    "      'boxes'.'height' : height of one box\n",
    "    '''\n",
    "    if not os.path.exists(json_file):\n",
    "        raise Exception(\"{0} is not exist\".format(json_file))\n",
    "\n",
    "    with open(json_file, 'r') as file:\n",
    "        json_info = json.load(file)\n",
    "    results = []\n",
    "    for info in json_info:\n",
    "        digit_info = {}\n",
    "        digit_info['filename'] = info['filename']\n",
    "\n",
    "        boxes = info['boxes']\n",
    "        x1 = int(np.min([box['left'] for box in boxes]))\n",
    "        y1 = int(np.min([box['top'] for box in boxes]))\n",
    "        x2 = int(np.max([box['left'] + box['width'] for box in boxes]))\n",
    "        y2 = int(np.max([box['top'] + box['height'] for box in boxes]))\n",
    "\n",
    "        digit_info['bbox_x1'] = x1\n",
    "        digit_info['bbox_y1'] = y1\n",
    "        digit_info['boxes'] = np.array([{ name : int(box[name]) for name in ['left', 'top', 'width', 'height']}  for box in boxes])\n",
    "        digit_info['bbox_width'] = x2 - x1\n",
    "        digit_info['bbox_height'] = y2 - y1\n",
    "        digit_info['labels'] = np.array([int(box['label']) for box in boxes])\n",
    "        results.append(digit_info)\n",
    "    return results\n",
    "\n",
    "train_json_file_path = os.path.join(jsons_root, 'train/digitStruct.json')\n",
    "test_json_file_path = os.path.join(jsons_root, 'test/digitStruct.json')\n",
    "train_json_info = get_json_information(train_json_file_path)\n",
    "test_json_info = get_json_information(test_json_file_path)\n",
    "print(\"Train json info : \\n\", train_json_info[0:5])\n",
    "print(\"=\" * 50)\n",
    "print(\"Test json info : \\n\", test_json_info[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.draw "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and analyze data first\n",
    "1. Load mat data and transform to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digit_struct_file = digit_struct_files[0]\n",
    "#digit = sio.loadmat(digit_struct_file)\n",
    "# use scipy.io at first, but \"NotImplementedError: Please use HDF reader for matlab v7.3 files\" happens,\n",
    "# after google, use h5py instead\n",
    "print(digit_struct_file)\n",
    "mat_file = h5py.File(digit_struct_file, 'r')\n",
    "mat_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(mat_file))\n",
    "for mat in mat_file:\n",
    "    print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "digitStructName = mat_file['digitStruct']['name']\n",
    "digitStructBbox = mat_file['digitStruct']['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(''.join([chr(c) for c in mat_file[digitStructName[0][0]].value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
